apiVersion: batch/v1
kind: Job
metadata:
  name: {{ template "llama-cpp.fullname" . }}
  namespace: {{ template "llama-cpp.namespace" .}}
spec:
  template:
    spec:
      containers:
      - name: benchmark-model
        image: {{ .Values.deployment.image.repository }}:{{ .Values.deployment.image.tag }}
        imagePullPolicy: {{ .Values.deployment.image.pullPolicy }}
        command: ["./llama-bench", "-m", "/data/{{ .Values.model }}/{{ .Values.modelOptions.quantize.convertOutput }}", "-p", "{{ .Values.modelOptions.benchmark.promptNumber }}", "-n", "{{ .Values.modelOptions.benchmark.textGenerationNumber }}", "-b", "{{ .Values.modelOptions.benchmark.batchNumber }}", "-o", "{{ .Values.modelOptions.benchmark.output }}"]
        volumeMounts:
        - name: shm
          mountPath: /dev/shm
        - name: model-storage
          mountPath: /data
          readOnly: true
      restartPolicy: Never
      volumes:
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 1Gi
      - name: model-storage
        persistentVolumeClaim:
          claimName: {{ template "llama-cpp.fullname" . }}
      {{- with .Values.deployment.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.deployment.tolerations }}
      tolerations:
        {{- toYaml . | nindent 6 }}
      {{- end }}
  completions: 1
  backoffLimit: 10