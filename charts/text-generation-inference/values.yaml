nameOverride: text-generation-inference

fullnameOverride: ""

namespaceOverride: ""

instanceLabelOverride: ""

global:
  # -- Number of old deployment ReplicaSets to retain. The rest will be garbage collected.
  revisionHistoryLimit: 3

  # -- If defined, a imagePullPolicy applied to all Argo CD deployments.
  imagePullPolicy: IfNotPresent

  # -- Secrets with credentials to pull images from a private registry.
  imagePullSecrets: []

  # -- Common labels for the all resources.
  additionalLabels: {}
    # app: chat-ui

  # -- Labels for the all deployed Deployments.
  deploymentLabels: {}

  # -- Labels for the all deployed pods.
  podLabels: {}

  # -- Annotations for the all deployed Deployments.
  deploymentAnnotations: {}

  # -- Annotations for the all deployed Pods.
  podAnnotations: {}

  # -- Toggle and define pod-level security context.
  # @default -- `{}` (See [values.yaml])
  securityContext: {}
  #  runAsUser: 999
  #  runAsGroup: 999
  #  fsGroup: 999

  # -- Mapping between IP and hostnames that will be injected as entries in the pod's hosts files.
  hostAliases: []
  # - ip: 10.20.30.40
  #   hostnames:
  #   - git.myhostname

  # -- Node selector for all resources. If both nodeSelector and affinity are set, they must both match for the pod to be scheduled onto a node.
  nodeSelector: {}

  # -- Affinity for all resources. If both nodeSelector and affinity are set, they must both match for the pod to be scheduled onto a node.
  affinity: {}

  # -- Tolerations for all resources.
  tolerations: []

  # -- Deployment strategy for the all deployed Deployments.
  deploymentStrategy: {}
    # type: RollingUpdate
    # rollingUpdate:
    #   maxSurge: 25%
    #   maxUnavailable: 25%

tgi:
  name: text-generation-inference

  image:
    repository: ghcr.io/huggingface/text-generation-inference
    # tag: sha-96b7b40
    pullPolicy: IfNotPresent

  extraEnv: []

  deploymentLabels: {}

  podLabels: {}

  deploymentAnnotations: {}

  podAnnotations: {}

  resources: {}
    # requests:
    #   cpu: 100m
    #   memory: 2Gi
    # limits:
    #   # Recommended to use large limits when web search is enabled
    #   cpu: "4"
    #   memory: 6Gi

  tolerations: []

  nodeSelector: {}

  affinity: {}

  deploymentStrategy: {}

  # TODO
  replicas: 1
  
  # -- Metrics configuration for Text Generation Inference service.
  metrics:
    # -- Deploy metrics service.
    enabled: false
    serviceMonitor:
      # -- Enable a Prometheus ServiceMonitor.
      enabled: false
      # -- Prometheus ServiceMonitor interval.
      interval: 30s
      # -- Prometheus ServiceMonitor scrapeTimeout. If empty, Prometheus uses the global scrape timeout unless it is less than the target's scrape interval value in which the latter is used.
      scrapeTimeout: ""
      # -- Prometheus [RelabelConfigs] to apply to samples before scraping.
      relabelings: []
      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion.
      metricRelabelings: []
      # -- Prometheus ServiceMonitor selector.
      selector: {}
        # prometheus: kube-prometheus

      # -- Prometheus ServiceMonitor scheme.
      scheme: ""
      # -- Prometheus ServiceMonitor tlsConfig.
      tlsConfig: {}
      # -- Prometheus ServiceMonitor namespace.
      namespace: "" # "monitoring"
      # -- Prometheus ServiceMonitor labels.
      additionalLabels: {}
      # -- Prometheus ServiceMonitor annotations.
      annotations: {}

  # TODO
  ingress:
    enabled: false

  model: meta-llama/Meta-Llama-3-8B-Instruct

  modelOptions:
    # quantize: bitsandbytes

  modelStorage:
    accessModes:
    - ReadWriteOnce
    size: 100Gi

  huggingFaceToken:
    secretName: hugging-face-token
    secretKey: token
